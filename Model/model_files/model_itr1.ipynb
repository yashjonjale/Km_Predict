{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://pypi.repo.test.hhu.de/simple/\n",
      "Collecting typing-extensions==3.7.4\n",
      "  Downloading http://pypi.repo.test.hhu.de/packages/27/aa/bd1442cfb0224da1b671ab334d3b0a4302e4161ea916e28904ff9618d471/typing_extensions-3.7.4-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: xgboost in /home/yashjonjale/.local/lib/python3.10/site-packages (2.0.3)\n",
      "Collecting xgboost\n",
      "  Downloading http://pypi.repo.test.hhu.de/packages/5b/c2/ffab644d6dabb5903a3754bac87a76f3c99828ebe62261975f53472d3035/xgboost-2.1.0-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /usr/lib/python3/dist-packages (from xgboost) (1.21.5)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /home/yashjonjale/.local/lib/python3.10/site-packages (from xgboost) (2.19.3)\n",
      "Requirement already satisfied: scipy in /usr/lib/python3/dist-packages (from xgboost) (1.8.0)\n",
      "Downloading http://pypi.repo.test.hhu.de/packages/27/aa/bd1442cfb0224da1b671ab334d3b0a4302e4161ea916e28904ff9618d471/typing_extensions-3.7.4-py3-none-any.whl (20 kB)\n",
      "Downloading http://pypi.repo.test.hhu.de/packages/5b/c2/ffab644d6dabb5903a3754bac87a76f3c99828ebe62261975f53472d3035/xgboost-2.1.0-py3-none-manylinux_2_28_x86_64.whl (153.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.9/153.9 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: typing-extensions, xgboost\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.9.0\n",
      "    Uninstalling typing_extensions-4.9.0:\n",
      "      Successfully uninstalled typing_extensions-4.9.0\n",
      "  Attempting uninstall: xgboost\n",
      "    Found existing installation: xgboost 2.0.3\n",
      "    Uninstalling xgboost-2.0.3:\n",
      "      Successfully uninstalled xgboost-2.0.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anyio 4.2.0 requires typing-extensions>=4.1; python_version < \"3.11\", but you have typing-extensions 3.7.4 which is incompatible.\n",
      "async-lru 2.0.4 requires typing-extensions>=4.0.0; python_version < \"3.11\", but you have typing-extensions 3.7.4 which is incompatible.\n",
      "pydantic 2.6.3 requires typing-extensions>=4.6.1, but you have typing-extensions 3.7.4 which is incompatible.\n",
      "pydantic-core 2.16.3 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 3.7.4 which is incompatible.\n",
      "torch 2.2.1 requires typing-extensions>=4.8.0, but you have typing-extensions 3.7.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed typing-extensions-3.7.4 xgboost-2.1.0\n",
      "Looking in indexes: http://pypi.repo.test.hhu.de/simple/\n",
      "Requirement already satisfied: typing-extensions==3.7.4 in /home/yashjonjale/.local/lib/python3.10/site-packages (3.7.4)\n",
      "Requirement already satisfied: biopython in /home/yashjonjale/.local/lib/python3.10/site-packages (1.83)\n",
      "Requirement already satisfied: numpy in /usr/lib/python3/dist-packages (from biopython) (1.21.5)\n",
      "Looking in indexes: http://pypi.repo.test.hhu.de/simple/\n",
      "Requirement already satisfied: typing-extensions==3.7.4 in /home/yashjonjale/.local/lib/python3.10/site-packages (3.7.4)\n",
      "Requirement already satisfied: hyperopt in /home/yashjonjale/.local/lib/python3.10/site-packages (0.2.7)\n",
      "Requirement already satisfied: numpy in /usr/lib/python3/dist-packages (from hyperopt) (1.21.5)\n",
      "Requirement already satisfied: scipy in /usr/lib/python3/dist-packages (from hyperopt) (1.8.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from hyperopt) (1.16.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/yashjonjale/.local/lib/python3.10/site-packages (from hyperopt) (3.2.1)\n",
      "Requirement already satisfied: future in /usr/lib/python3/dist-packages (from hyperopt) (0.18.2)\n",
      "Requirement already satisfied: tqdm in /home/yashjonjale/.local/lib/python3.10/site-packages (from hyperopt) (4.66.2)\n",
      "Requirement already satisfied: cloudpickle in /home/yashjonjale/.local/lib/python3.10/site-packages (from hyperopt) (3.0.0)\n",
      "Requirement already satisfied: py4j in /home/yashjonjale/.local/lib/python3.10/site-packages (from hyperopt) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --user -i http://pypi.repo.test.hhu.de/simple/ --trusted-host pypi.repo.test.hhu.de typing-extensions==3.7.4 --upgrade xgboost\n",
    "!{sys.executable} -m pip install --user -i http://pypi.repo.test.hhu.de/simple/ --trusted-host pypi.repo.test.hhu.de typing-extensions==3.7.4 --upgrade biopython\n",
    "\n",
    "!{sys.executable} -m pip install --user -i http://pypi.repo.test.hhu.de/simple/ --trusted-host pypi.repo.test.hhu.de typing-extensions==3.7.4 --upgrade hyperopt\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK, rand\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# path = \"/home/not81yan/km_predict_proj/Model/Dataset\"\n",
    "path = os.getcwd()+\"/../rough/final_data_32000.npy\"\n",
    "arr = np.load(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3200, 2563)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_arr = arr[:1000,:]\n",
    "X = arr[:, 3:]\n",
    "y = arr[:, 2]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "D_train=xgb.DMatrix(data=X_test, label=y_test)\n",
    "D_test=xgb.DMatrix(data=X_train, label=y_train)\n",
    "\n",
    "#now do k-fold cross validation split of X_train, y_train   \n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3200, 2560)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_test = []\n",
    "splits_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(X_train):\n",
    "    splits_test.append(test_index)\n",
    "    splits_train.append(train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_mse_gradient_boosting(params):\n",
    "    num_round = params['num_rounds']\n",
    "    params = {\n",
    "        'max_depth': int(np.round(params['max_depth'])),\n",
    "        'learning_rate': params['learning_rate'],\n",
    "        'min_child_weight': params['min_child_weight'],\n",
    "        'reg_alpha': params['reg_alpha'],  # L1 regularization\n",
    "        'reg_lambda': params['reg_lambda'],  # L2 regularization\n",
    "        'tree_method':   # Use CPU for training\n",
    "            #select cpu for training\n",
    "            'hist',\n",
    "        \n",
    "        # 'predictor': 'gpu_predictor',  # Use GPU for predictions\n",
    "        'sampling_method': 'uniform',\n",
    "        'eval_metric': 'rmse'\n",
    "    }\n",
    "    MSE = []\n",
    "    R2 = []    \n",
    "    for i in range(5):\n",
    "        train_index, test_index  = splits_train[i], splits_test[i]\n",
    "        dtrain = xgb.DMatrix(X_train[train_index], label = y_train[train_index])\n",
    "        dvalid = xgb.DMatrix(X_train[test_index])\n",
    "        bst = xgb.train(params, dtrain, int(num_round), verbose_eval=False)\n",
    "        y_valid_pred = bst.predict(dvalid)\n",
    "        MSE.append(np.mean(abs(np.reshape(y_train[test_index], (-1)) - y_valid_pred)**2))\n",
    "        R2.append(r2_score(np.reshape(y_train[test_index], (-1)),  y_valid_pred))\n",
    "    return(-np.mean(R2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?trial/s, best loss=?]"
     ]
    }
   ],
   "source": [
    "\n",
    "space = {\n",
    "    'max_depth': hp.quniform('max_depth', 3, 15, 1),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "    # 'n_estimators': hp.quniform('n_estimators', 100, 500, 1),\n",
    "    # 'gamma': hp.uniform('gamma', 0, 0.5),\n",
    "    # 'min_child_weight': hp.quniform('min_child_weight', 1, 10, 1),\n",
    "    # 'subsample': hp.uniform('subsample', 0.5, 1),\n",
    "    # 'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "    # 'reg_alpha': hp.uniform('reg_alpha', 0, 1),  # L1 regularization\n",
    "    # 'reg_lambda': hp.uniform('reg_lambda', 0, 1)  # L2 regularization\n",
    "    # \"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 1),\n",
    "    # \"max_depth\": hp.uniform(\"max_depth\", 4,12),\n",
    "    #\"subsample\": hp.uniform(\"subsample\", 0.7, 1),\n",
    "    \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 5),\n",
    "    \"reg_alpha\": hp.uniform(\"reg_alpha\", 0, 5),\n",
    "    \"max_delta_step\": hp.uniform(\"max_delta_step\", 0, 5),\n",
    "    \"min_child_weight\": hp.uniform(\"min_child_weight\", 0.1, 15),\n",
    "    \"num_rounds\":  hp.uniform(\"num_rounds\", 20, 200)\n",
    "}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn = cross_validation_mse_gradient_boosting, space = space,\n",
    "            algo=rand.suggest, max_evals = 250, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters\n",
    "print(\"Best parameters found by Hyperopt:\")\n",
    "print(best)\n",
    "num_round = best['num_rounds']\n",
    "del best['num_rounds']\n",
    "params={'max_depth': int(np.round(best['max_depth'])),\n",
    "        'learning_rate': best['learning_rate'],\n",
    "        'min_child_weight': best['min_child_weight'],\n",
    "        'reg_alpha': best['reg_alpha'],  # L1 regularization\n",
    "        'reg_lambda': best['reg_lambda'],  # L2 regularization\n",
    "        'tree_method': 'gpu_hist',  # Use GPU\n",
    "        'predictor': 'gpu_predictor',  # Use GPU for predictions\n",
    "        'sampling_method': 'gradient_based',\n",
    "        'eval_metric': 'rmse'}\n",
    "best_model = xgb.train(params, xgb.DMatrix(X_train,label=y_train), int(num_round), verbose_eval=False)\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the final model on the test set\n",
    "test_accuracy = best_model.score(X_test, y_test)\n",
    "print(\"Test Accuracy: {:.2f}\".format(test_accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
