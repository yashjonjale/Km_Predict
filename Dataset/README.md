# Pipeline

## files in the Pipeline till now

brenda -> create.py -> {ec_num}-km.csv -> {ec_num}-engg.csv, {ec_num}-km.csv -> pre_process_tables.py -> "substr2substr_id.json", {directory}{f_fname}_{str(substr2substr_id[key])}_sub.csv" -> ... 

## Pipeline I

### create.py (leverages mapping between substrates and references available in comments)

from the benda database, it extracts tables (for each ec class) whose entries contain proteins, uniprot ids, mutation changes (if applicable) and substrate name

### pre_process_tables.py

from the tables generated by create.py, we create new table that group ec class tables with respect to substrates, km-values (take means, if multiple km values), and form final tables (for each each ec class substate pairs) with uniprot ids, substate, if not wild type then the mutation, and the mean km_values of course

it also maps substrate names to integer ids for easier computation and dumps the json file out

### remove_no_mutations.py

deletes all files in which no row has mutations

## Transfer to local

trnasfer.sh and add_seq.py

### add_seq.py

adds the sequences after modification


## Pipeline II

### add_esm.py 

adds esm mean embeddings to each row for the modified sequence



## Local run II

### make_pairs.py

Makes pairs naively and creates ecnum_subid_pairs.csv
Now, locally, you can get the alignment scores

make the correlation plots between 


## Pipeline_IV

### into_numpy.py

makes a npz format by concatenating all tables

## Go to model

### to_model.sh

moves the npz file to model directory